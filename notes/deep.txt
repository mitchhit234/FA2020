Lec 1 Intro:

What is deep learning?

Deep learning is a class of Neural Network Algorithims

Neural networks are a branch of Machine learning

Machine learning is a branch of Artifical Intelligene


Deep Learning <- Neural Networks <- Machine Learning <- Arifitcal Intelligence



Artifical Intelligence - How to make computers do things at which, so far, humans are better (EX: Cars that drive themselves, Computers that play Chess)



Dijkstra asks the questions: Can machines think?
Student say no...
Then he asks: Can submarines swim?
Students mostly say no
Then he asks: Can planes fly?
Everyone says yes

Dijkstra's perspective is that thinking is computation, and in essence, computers can think



New definition for A.I. - the field that studies the synthesis and analysis of computational agents that act intelligently

Agent - an entity that acts in an environment

Computational - behavior can be described in terms of computation

Acting Intelligenly - Does the agent:
Do what is appropriate for its circumstances and goals?
Is flexible in changing to its environments and changing goals?
Learns from experience?
Makes the appropriate choices given its perceptual and computational liminations?



A.I. is not a field about how to imitate humans, instead it is a broad collection of different techniques and algorithims each intended to a particular purpose




Machine Learning is the branch of A.I. that studies learning mechanisims for Intelligent Agents

Learning:
- The range of behaviors is expanded; the agent can do more
- The accuracy on tasks is improved; the agent can be better
- The speed on tasks is improved; the agent can be faster




Neural Networks:
A computational learning mechanisim inspirde by the function of biological neurons (Not exactly a simulation)

Neural Networks are usually used for supervised learning. Neural Networks are used to recognize patterns from training data

But as the size of the data grows, the time needed for learning grows at an exponential rate (The curse of dimensionality)

Deep learning is what is used to counter the effects of the curse of dimensionality




Deep Learning:
A class of Neural Network Architectures and Algorithms to address problems arising from large input data and large networks






Lec 2 A.I. and Agents:


Goals of AI:
Scientific Goal - to understand the principles that make intelligent behavior possible in natural or artifical systems
Engineering Goal - design of useful, intelligent artifacts


Inputs to an agent:
Abilities - the set of actions an agent can perform
Goals/Preferences - what the agent wants, its values
Prior Knowledge - knowledge that the agent starts off knowing
History - Current stimuli (input from the environment) and past stimuli


Example Agent: Autonomus car

Abilities - steer, accelerate, brake
Goals - get to the destination quickly and safely
Prior knowledge - street maps, road sign meanings, recognize various road blocks
Stimuli - cameras for vision, GPS, microphones
Past experiences - success/failures from previous trips




Aspects of Intelligent Agents:

Representation - How does the agent internally represent relevant information? With the Knowledge Base (abilities, preferences, prior experiences)

How does the agent characterizes its goal?
Optimal - the best solution according to given criteria
Satisficing - a good enough solution by some criteria
Approximate - mesaure of quality is good enough
Probable - something like a good solution

When does the computational work of the agent take place?
Design - done by designer
Offline - done by agent before acting, provides part of knowledge base
Online - done by agent between reciving stumli and acting







Lec 3 The Agent Design Space:

9 choices designers make when desiging intelligent agents:

1. Modularity
How is the agent organized internally?
Flat - no decomposition
Modular - seperate modules
Hierarchical - modules recursivley decompose into each other (pyramid of modules)

2. Planning Horizon
How far ahead does the agent plan?
Static - the world does not change
Finite state planning - plans a fix # of steps
Indefinite stage planning - plans a finite (non-predetermined) # of steps
Infinite stage planning - plans are ongoing and repeated

3. Representation
How does the agent describe the world?
Explicit - states of the world are enumerated
Features - using variables with discrete values
Indivudual and Relations - predicate logic

4. Computational Limits
Perfect Rationality - agent can always compute the best action
Bounded rationality - agent must make good decisions regarding its limitations (time, memory, perceptual)

5. Learning 
Knowledge is given
Knowledge is aqquired from data/past experience

6. Uncertainty
Sensing Uncertainty - Fully obserable world and partially observable
Effect Uncertainty - Deterministic vs stochastic (subject to uncertainty) actions

7. Preference 
How are the goals described?
Specific goal = complex preferences

8. Number of Agents
Single Agent vs Multipule Agents
Adversarial or Cooperative?

9. Interaction
Offline - reason before acting 
Online - reasoning while interacting with the environment




Lec 4 Mathematical Preliminaries:

Function: A mapping from a set A to a set B
A = domain
B = range

EX: f: R -> R     f(x) = a + bx
x is input, a and b are parameters

Let f: A -> B

Total - f is defined for every element of A
Partial - there exists a in the set of A where f is undefined
Surjection - every element of B is assigned to an element from A
Injection - every element in A is assigned a unique element in B
Bijection - a surjection and injection exists


EX: X is a subset of A

Image (of X) - the set of elements Y in the subset of B (range) assigned to the elements of X   f[X] = Y

Inverse Image - the set of inputs X assigned to a set of outputs Y
F^-1[Y] = X


A monotone function is when x<y then f(x) < f(y), or if x>y, then f(x) > f(y)

A continuous function is a function with no gaps

A limit is a value that a function's output approaches but never reaches

F is continuous at a point if and only if:
- f(a) is defined
- lim f(x) as x -> a exits
- lim f(x) as x-> a - f(a)



Differentiaton

The derivative of f(x) at point x_1 is the slope of f(x) at point x_1
f'(x) = df/dx = dy/dx


Vectors

Scalar - a single value

n-Vector - a sequence of n scalars
EX: x (x_1, x_2, x_3... x_n)
x_i are the components of x

Scalar : point in a line
2-vector : point in 2D space
3-vector : point in 3D space

The basic vectors:
e_1 = (1,0,0)
e_2 = (0,1,0)
e_3 = (0,0,1)

s_1e_1 + s_2e_2 + s_3e_3

The dot product has a scalar answer

Two vectors are orthogonal if the dot product between the vectors is 0



Lec 5 More Math:

A matrix is a vector of vectors. A two-dimensional table of numbers arr[][]
a_ij represents a value in a matrix, i is the row and j is the column
1xn matrix is a vector of 1 row, nx1 matrix is a column vector

Operations on Matricies
The transposition of mxn matrix A, A^T, is then nxm matrix B where a_ij = b_ji (flipping rows and columns)
A matrix is symetric is A = A^T

Mulitplying a matrix by a scalar sA is multiplying all the values in a matrix by s. Same goes with a function of the matrix f(A)

Adding matricies A+B gives you matrix C
Matrix A and B have to have the same dimensions

Multiplying matricies A and B gives you C, where C_ij = the summation from k=1 to p of a_ik x b_kj 
The rows of A must equal the columns of B, and the rows of B must equal the columns of A (in length)
Matrix multiplication is non-communiative, AB != BA

A zero matrix is a matrix of all 0's
A unit matrix (I) is a square matrix where a_ij is equal to one if i=j, otherwise a_ij = 0
An orthogonal matrix is a square matrix where A x A^T - A^T x A = I_n



Function Minimization:
Given f(x), find value c where f(x) is minmized 



Lec 6 Machine Learning

Learning's definition here is the ability to improve one's behavior with experience
Improved through range of actions, accuracy of tasks, and speed of processes

Three components of a machine learning problem:
- Data is the experiences from which the agent is going to learn (aqquired at setup or during runtime)
- Task is the action that we are trying to improve 
- Measure of improvement (the three improvement categories listed above)


Common Machine Learning Tasks:
Supervised Learning - learn from example inputs and outputs
Unsupervised Learning - find groupsing from example data
Reinforcement Learning - find what to do based on rewards and punishment
Analytic Learning - find ways of reasoning faster using experience
Inductive Logic Programming - build rich models in terms of logic programs
Statistical Relational Learning - learn relational representations of the data


When is feedback given?
Supervised Learning - after every example
Unsupervised Learing - no feedback
Reinforcement Learning - after a sequence of actions

Online vs Offline learning, when offline examples are avaliable to the agent before acting, as where online learning is when the examples arrive as the agent is acting


Measuring Success
Success is measure on the task not the data (output, not the input)
Example data drives the search
There can be noise in data, missing examples/misclassified


Bias 
A tendency to prefer one model over another



Lec 7 Supervised Learning:

Data is represented as a collection of examples, E
Each collection contains inputs and outputs

Given the input vector of E, predict the output (given ->x predict ->y)
Regression output is when its a continuous value
Classification output is when its a boolen value (yes or no)

Measuring Error
Absoulte Error (L_1 error) - sum over every example of the absolute difference between the expect output minus the output of our learner
Sum-OfSquare (L_2)^2 - absolute error squared
Worst-Case-Error (L_infinity) - max(absolute error (of a single value, not sum like absolute error)) 
Error Count (L_0) - # of times expected output is different from learner output

Data Noise - includes mesuaring errors, incomplete/wrong data, meaning it can not be fully relied upon
Overfitting - the learner specalizes on details of the training data

Simple model will have more errors but will be easier to learn
Complex modeel will have less error, be harder to learn, and tend to overfit

Data can be seperated into a training set and testing set
Training set (usually 10% of testing set) is used to train the learner
Then, the learner is evaluated against the testing set
This stratergy helps identify overfitting




Linear Regression

The data is a set E of examples em where e = x_1, x_2, ..... x_n or the vector x
we hope to find the values of x_i, y for examples e
predict y from the vector x

Model: Linear Regression
yhat(e) = b + w_1x_1(e) + w_2x_2(e) ... w_nx_n(e), w being out weight variables

find w_1 ... w_n that minimizes Error(E,w)
Use Gradient Descent (equation in slides)
Initalize the w's randomly
Compute for each weight its measurement of error
Update each w by its associated error
Repeat until a specfied stopping condition is reached

Incremental Gradient Descent
update a w after each example
approaches solution faster, does not converge

Stochastic Gradient Descent
chooses examples at random

Batched Gradient Descent
update w after some number of examples (number can be changed as well)




Classification

Squashing Functions

Step Function
1 if x > 0, otherwise 0

Sigmoid (logistic) Function
1/(1+e^(-x))


